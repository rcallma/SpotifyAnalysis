{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "baf6468c",
   "metadata": {},
   "source": [
    "Success in the music industry is measured in different ways for different people. Some musicians would rather keep underground music alive by not casting into the same mold as most popular artists while other musicians might want to see their music on Billboard charts. Most executives are typically in the business of making money. For a record label to be financially successful, they need to sign artists with qualities that are marketable to a wide audience. Can the popularity of a song be predicted based on song traits from data collected from Spotify? Spotify is the most widely used streaming service and shares its data free for any developer to access. Therefore, it makes the most sense to take advantage of this data source. This analysis will benefit record labels by offering a set of characteristics that the most popular music has in common. \n",
    "\n",
    "Hypothesis: There are characteristics of a song that will indicate whether it will have commercial success, defined by having a score in the top 12% of popularity on Spotify. \n",
    "\n",
    "Since the hypothesis specifically defines success as having a popularity in the top 12%, we will convert popularity to a categorical variable and use the Decision Tree Classifier model. Decision Tree uses a set of rules to make decisions. One advantage to Decision Tree is that it requires less pre-processing, and it does not require normalization. A disadvantage is that a small change in the data can change the structure of the model which might cause instability.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91dd0a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plt.style.use('ggplot')\n",
    "from sklearn import metrics\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.mode.chained_assignment = None\n",
    "desired_width = 320\n",
    "pd.set_option('display.width', desired_width)\n",
    "pd.set_option(\"display.max_columns\", 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59d99870",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('tracks.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b99a2954",
   "metadata": {},
   "source": [
    "The data used for this analysis was downloaded from Kaggle. The dataset is originally from the Spotify API which is open source and free to use for developers. The dataset contains 20 variables and 586,672 rows. Each row is a song. The variables are ID, name, popularity, duration_ms, explicit, artists, id_artists, release_date, danceability, energy, key, loudness, mode, speechiness, acousticness, instrumentalness, liveness, valence, tempo, and time_signature. Some of these self-explanatory. Danceability is measured from 0 - 1.0. It is defined as how a track is for dancing based on a number of elements such as tempo, rhythm stability, beat strength, and overall regularity. Acousticness is scored from 0 – 1.0 based on how acoustic the song is. Energy (also measured from 0 – 1.0) is defined as an upward motion in the music that will keep the listener engaged. As an example, higher energy songs have busier drums and more intense vocals. Instrumentalness (0 – 1.0) is a measure of how many vocals are in the song. Less vocals gives a higher instrumentalness score. Liveness (0 – 1.0) is scored based on if a song was recorded with a live audience and how well the listener can hear the audience. Speechiness (0 – 1.0) is scored based on how much spoken word the song has. \n",
    "An advantage of downloading from Kaggle is that I don’t need to sign up for a developer account on Spotify which makes things easier by allowing me to skip over those steps. A disadvantage is that it doesn’t contain a completely up to date dataset. However, the dataset is only a few months old so it shouldn’t make too much of a difference for what we are using it for. \n",
    "\n",
    "The first step is to split popularity into bins to create a 50/50 split. This will tell us that 12% of songs have a score of 50 or above. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51f7aec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.870723\n",
       "1    0.129277\n",
       "Name: popular, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split popularity into bins to create a categorical variable 'popular'\n",
    "df['popular'] = pd.cut(x=df['popularity'], bins=[-1, 49, 100], labels=[0, 1])\n",
    "df['popular'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c6fb0a",
   "metadata": {},
   "source": [
    "For a classifier model we will only use variables with numeric score so we can delete all the other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcffe069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep continuous numerical variables and our target variable 'popular'\n",
    "del df['popularity']\n",
    "del df['id']\n",
    "del df['name']\n",
    "del df['release_date']\n",
    "del df['artists']\n",
    "del df['id_artists']\n",
    "del df['time_signature']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4a19d3",
   "metadata": {},
   "source": [
    "Now we can split the data into test and train sets and fit the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fca3518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split test and train sets\n",
    "y = df['popular']\n",
    "X = df.drop('popular', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "658a66ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adda71ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "dt = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "892556de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using test set\n",
    "y_pred = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43b31596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[90833 11485]\n",
      " [10405  4612]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.89    102318\n",
      "           1       0.29      0.31      0.30     15017\n",
      "\n",
      "    accuracy                           0.81    117335\n",
      "   macro avg       0.59      0.60      0.59    117335\n",
      "weighted avg       0.82      0.81      0.82    117335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix and classification report\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('Classification Report')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0eb32c4",
   "metadata": {},
   "source": [
    "The output is quite better than before as it is now accurately predicting 29% of songs that are in the top half of the popularity column. The recall is 31% which is the model’s ability to find all positive instances. The f1 of 30% is the percent of positive predictions that were correct.That means that it accurately predicted a song in the top 12% of all songs 30% of the time. If I were a music executive and 1 in 3 songs I release on my record label ranked in the top 12% of popularity I would consider that very successful.\n",
    "\n",
    "The analysis was limited, however, in that it didn’t include obvious factors such as name recognition (an artist who is already popular will have a much better chance of releasing a popular song).\n",
    "\n",
    "One way to take this analysis further would be to incorporate artist info such as the number charted songs/albums an artist has. Another way we could go deeper into this analysis would be to use a neural network model to classify a song as popular or not popular based on the spectrogram of the audio file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
